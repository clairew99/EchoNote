# 전문가 리뷰

날짜: 2024년 9월 6일
상태: 진행 중

### 팀 소개 및 프로젝트 소개

백 4 프론트 2

주제 변경

멘토님 :  AI특강 때 오셨음, AI 교육 쪽 

### 질문

*명세서에 대한 질문보다는 기술 쪽 질문 위주로!

~~프로젝트 소개~~

A. 

**Q1. 메인주제 질문**

A. 회의실에서 회의하는 내용을 녹음을 기반으로 회의록 작성하고, 투두리스트 작성해주는 프로젝트 사내에서 진행중

구어체는 정확도가 60~70으로 높지 않음. 보편적이지 않은 단어나 한글이랑 섞이는 영어단어로 인해 후처리가 필요하다.

후처리 → 지금은 LLM을 통해 STT 된 데이터를 넣고 보정작업 → 전체적 맥락 유지랑 흐름 파악 정도에는 괜찮음

키워드 보정 → 용어 사전을 만들거나 단어들이 사람이 인지하고 보강할 수 있는 프로세스를 만든다

QN2 오디오 모델 (알리바바) : Whisper + Qn7b 음성 통해 나온 텍스트를 보정하는 모델

- [**알리바바 클라우드, 최신 버전 LLM '큐원2.5' 출시**](https://www.aitimes.com/news/articleView.html?idxno=159539)
- [https://github.com/QwenLM/Qwen2](https://github.com/QwenLM/Qwen2)
- [**알리바바의 llm 모델 qwen2 사용해보기 (feat.놀라운 한국어실력)**](https://drfirst.tistory.com/entry/%EC%95%8C%EB%A6%AC%EB%B0%94%EB%B0%94%EC%9D%98-llm-%EB%AA%A8%EB%8D%B8-qwen2-%EC%82%AC%EC%9A%A9%ED%95%B4%EB%B3%B4%EA%B8%B0-feat%EB%86%80%EB%9D%BC%EC%9A%B4-%ED%95%9C%EA%B5%AD%EC%96%B4%EC%8B%A4%EB%A0%A5)

**Q2. 추가 주제 관련된 질문**

A2-1. 실시간으로 전화통화가 이루어지는데 특정 키워드에 필터링이 적용되었을 떄 딜레이 문제를 해결할 수 있을지

https://www.youtube.com/playlist?list=PLOXw6I10VTv8VOvPNVQ8c4D4NyMRMotXh

GPT4는 STT, TTS 가 없다

아예 응답 자체를 음성으로 내놓게 한다

- 텍스트 변환처리 과정을 거치지 않음

음성 톤, 주변 환경, 흥얼거리는 소리는 텍스트로 불가능함.
그런 게 다 인풋, 아웃풋으로 나올 수 있다.

저게 곧 나올거다로 기대를 해도 되고, 저 테스트 과정이 없다면 딜레이가 줄어들거다.
그래서 실시간 번역같은 기능이 가능할거다로 기대하고 있다.

현재 해결 방안은 우리 수준에서는 없다.
실제 고객 센터에서 하는 방법은 멀티 모달을 이용하기보단 생성 속도가 빠른 딥러닝 모델을 사용하거나 특정 패턴을 인식하는 형태로 사용하고 있다.
하지만                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       결국은 멀티모달, LLM쪽으로 넘어올 거 같다.

**A2-2. RVC 생성 음성을 구별할 수 있을까?**

여러 모델이 나오고 있기는 해서 기대가 되기는 하지만 ai로 생성된 음성을 식별하는 것은 아직은 어렵고, 점점 더  어려워질 것이다. 기술력이 올라가고 있긴 하니까.
예를 들어 음성의 스펙트럼 분석, 공명 주파수가 일관성 있게 나오는지, 피치의 변화가 일반 사람의 음성과 다른지, 부자연스러운 표현이나 말투를 하거나 전체 문맥이 불일치한지. 이런걸로 판단할 수는 있지만 점점 더 어려워질거다.
예를 들어 ai 생성 음악, 이게 ai를 통해 만든 음악인지 파악하기 어려워지고 있다.

**A2-3. MFCC** 

MFCC를 사용한 감정 분석 : 어렵다

어려울 것이다. 사전에 우리 서비스의 목적에 맞게 음성 데이터가 많이 필요하고 음성 데이터마다 라벨링이 되어 있는 고품질의 학습 데이터 필요. 음성 처리 시 주변 소리나 잡음같은 전처리 과정 신경 쓸 필요 존재.
감정을 분석하는데 있어 사람이 느꼈을 때도 애매한 중립적인 감정들이 많아 ai에서 어려운 부분이 있다. 어려운 기술 중 하나이지 않을까 라는 생각이 든다.

만약 gpt4가 공개가 되면 좀 나아질 거다. 단순히 텍스트가 아니라 말투가 숨겨진 감정까지도 LLM이 분석 할 수 있다.
유튜브를 보면 일부 사용자에게 공유돼서 그 후기를 남겨둔 영상들도 있다.

Q. 감정 분석이 어려운 기능이라고 하셨는데, 사진의 표정을 통해 감정 별로 %는 나타낼 수 있는데, 음성도 그런 식의 접근은 어려울까요?

A. 접근은 가능하지만 완전히 분류되기는 어렵다. 사진도 웃으면서 슬픈 표정을 짓는다 등의 그 미묘한 표정 같은 부분에서 어려움이 있기 때문에 그렇다

프로파일링 흥미로웠는데 아쉽다

레시피 데이터 확보가 필요할 것

Tip : Claude 의 프롬프트 생성기 도구를 사용해 진입하면 좋을 것

ex) API console > Generate a prompt > 우리가 만들고자 하는 것, 제공되는 데이터 입력

예시 음성 데이터도 생성할 수 있다

Q. 챗봇의 음성화?

A. [https://openai.com/index/teaching-with-ai/](https://openai.com/index/teaching-with-ai/)

선생님들이 수업계획을 세울 때 어떻게 AI와 상호작용 할 수 있는지

나온 프롬프트를 활용해 chat gpt 세팅 후 챗봇처럼 사용

필요한 데이터를 넣어준다

“아래 프롬프트 방식을 토대로 요리 레시피 정보를 알려주고, …”

팁 : Claude의 프롬프트 생성을 쓰면 좀 빠르게 할 수 있다.
api 콘솔 -> 프롬프트 생성 -> [ 음성으로 레시피 정보를 지급하는 서비스를 만들려고 합니다.
제공되는 것은 음성이 텍스트로 변환된 데이터가 제공이 되고, 레시피 상세 정보가 지급될 예정입니다. ]

하고 추가 고도화를 해서 생성하면 서비스를 만들기 위한 프롬프트를 작성해준다.
처음에 들어갈 것은 음성 -> 텍스트 데이터, 레시피 상세 정보를 쓰면 되는 프롬프트가 나온다.

돌려볼 데이터가 없으면 생성을 할 수 있다.

처음 시작은 프롬프트의 도움을 받아서 해보는 것도 나쁘지 않다.

<aside>
💡

System Prompt: You are a friendly and knowledgeable cooking assistant, helping people create delicious meals.
First, introduce yourself and ask what dish the user would like to cook today and for how many people. Wait for the user to respond. Do not proceed until the user answers.
Next, ask the user if they have any prior experience with the dish or if this is their first time making it. If they have experience, ask them to briefly explain what they know about the dish or any special steps they’ve used before. Wait for their response and do not assume their answer.
Then, ask if they have any dietary preferences or restrictions you should be aware of, such as vegetarian, gluten-free, etc. Wait for their answer before moving forward.
Once you have this information, provide a customized recipe with step-by-step instructions, including ingredient preparation, cooking techniques, and any equipment they will need. Explain why you are suggesting specific techniques or ingredients and how they will contribute to the success of the dish.
Ask the user if they have any questions or concerns about the process or if they would like to make any changes to the recipe. Wait for their response before proceeding.
If the user has any changes or concerns, work with them to adjust the recipe. Make sure to address any issues like ingredient substitutions, timing, or techniques based on their needs.
Finally, ask the user if they would like any additional tips for making the dish more flavorful or for troubleshooting any common problems. Wait for their response.
If the user is happy with the recipe and process, tell them they can return to this prompt at any time to ask for more help with future meals or to let you know how the dish turned out.

</aside>

샘플
-> open ai 블로그에 공개된 것이 있다.
open ai teaching with AI
[https://openai.com/index/teaching-with-ai/](https://openai.com/index/teaching-with-ai/)

ai와 어떻게 상호작용하면서 할 수 있는지.
필요한 정보를 프롬프트로 넣으면 티키타카가 가능하다.

- 다른 팀에서 참고로 가져온거
    
    알리바바에서 오디오 AI 관련 프레임워크를 새롭게 소개하며 2가지 모델을 공개
    SenseVoice
    
    - 고성능 다국어 음성 인식, 감정 인식, 오디오 이벤트 감지 모델
    - 낮은 지연시간, 50개 이상의 언어 지원 (한국어 포함)
    CosyVoice
        - 다국어, 음색, 감정 제어가 가능한 음성 생성 모델
        - 다국어 음성 생성, 제로샷 음성 생성, 언어간 음성 복제 등 수행 가능
    
    관련 모델들도 모두 HuggingFace에 공개되었고 코드도 Github에 공개되었습니다. 모델들은 Apache 2.0와 MIT 라이선스로 공개되어 상업적 이용도 가능합니다
    
    - 프로젝트 페이지: [https://fun-audio-llm.github.io/](https://fun-audio-llm.github.io/)
    - 깃허브 (SenseVoice): [https://github.com/FunAudioLLM/SenseVoice](https://github.com/FunAudioLLM/SenseVoice)
    - 깃허브 (CosyVoice): [https://github.com/FunAudioLLM/CosyVoice](https://github.com/FunAudioLLM/CosyVoice)
    - 논문 (CosyVoice): [https://fun-audio-llm.github.io/pdf/CosyVoice_v1.pdf](https://fun-audio-llm.github.io/pdf/CosyVoice_v1.pdf)
    - 데모 링크: [https://www.modelscope.cn/studios/iic/SenseVoice](https://www.modelscope.cn/studios/iic/SenseVoice)
    - HuggingFace: [https://huggingface.co/FunAudioLLM/SenseVoiceSmall](https://huggingface.co/FunAudioLLM/SenseVoiceSmall)
    - 자동화된 AI Agent 구현을 위한 이해와 경험을 높여야 합니다.
    [https://youtu.be/PooDMxNH_6o](https://youtu.be/PooDMxNH_6o)
    - AI Assistant 사례 : [https://www.getdot.ai/](https://www.getdot.ai/)
    
    2024-09-06 오전 10:50 • - 알리바바에서 오디오 AI 관련 프레임워크를 새롭게 소개하며 2가지 모델을 공개했습니다
    SenseVoice
    
    - 고성능 다국어 음성 인식, 감정 인식, 오디오 이벤트 감지 모델
    - 낮은 지연시간, 50개 이상의 언어 지원 (한국어 포함)
    CosyVoice
        - 다국어, 음색, 감정 제어가 가능한 음성 생성 모델
        - 다국어 음성 생성, 제로샷 음성 생성, 언어간 음성 복제 등 수행 가능
    
    관련 모델들도 모두 HuggingFace에 공개되었고 코드도 Github에 공개되었습니다. 모델들은 Apache 2.0와 MIT 라이선스로 공개되어 상업적 이용도 가능합니다
    
    - 프로젝트 페이지: [https://fun-audio-llm.github.io/](https://fun-audio-llm.github.io/)
    - 깃허브 (SenseVoice): [https://github.com/FunAudioLLM/SenseVoice](https://github.com/FunAudioLLM/SenseVoice)
    - 깃허브 (CosyVoice): [https://github.com/FunAudioLLM/CosyVoice](https://github.com/FunAudioLLM/CosyVoice)
    - 논문 (CosyVoice): [https://fun-audio-llm.github.io/pdf/CosyVoice_v1.pdf](https://fun-audio-llm.github.io/pdf/CosyVoice_v1.pdf)
    - 데모 링크: [https://www.modelscope.cn/studios/iic/SenseVoice](https://www.modelscope.cn/studios/iic/SenseVoice)
    - HuggingFace: [https://huggingface.co/FunAudioLLM/SenseVoiceSmall](https://huggingface.co/FunAudioLLM/SenseVoiceSmall)
    
    Robin 2024-09-06 오전 11:08 • 3. 음성 인식의 정확도를 높이기 위해 서버와 클라이언트 측에서 어떤 최적화 작업이 필요한지
    
    - 현재 회의 녹음 음성으로 회의록 작성하는 프로젝트를 하고 있는데 LLM 을 통해 후처리 하는 것이 효과가 좋았습니다.
    - Alibaba, 오디오 언어모델 Qwen2-Audio 의 경우 Whisper 에 자사의 Qwen2-7B 언어모델을 결합하였습니다.
    [https://github.com/QwenLM/Qwen2-Audio](https://github.com/QwenLM/Qwen2-Audio)[https://huggingface.co/Qwen/Qwen2-Audio-7B](https://huggingface.co/Qwen/Qwen2-Audio-7B)
    1. 음성 인식의 정확도를 높이기 위해 서버와 클라이언트 측에서 어떤 최적화 작업이 필요한지
    - 현재 회의 녹음 음성으로 회의록 작성하는 프로젝트를 하고 있는데 LLM 을 통해 후처리 하는 것이 효과가 좋았습니다.
    - Alibaba, 오디오 언어모델 Qwen2-Audio 의 경우 Whisper 에 자사의 Qwen2-7B 언어모델을 결합하였습니다.
    [https://github.com/QwenLM/Qwen2-Audio](https://github.com/QwenLM/Qwen2-Audio)[https://huggingface.co/Qwen/Qwen2-Audio-7B](https://huggingface.co/Qwen/Qwen2-Audio-7B)
    1. 카카오 서비스에서 실시간으로 LLM이 적극적으로 활용이 되는지. - 카카오톡 요약하기 및 말투 변경하기 기능 : [https://talktips.kakao.com/bridge/67](https://talktips.kakao.com/bridge/67)
    - 내부적으로 다양한 실험 시도 중
    1. 활용이 된다면 LLM을 사용할 경우 결과를 얻기까지 다소 시간(2~3초)이 걸리는데 시간이 걸려도 괜찮은 부분에서만 쓰는지 그게 아니라면 LLM의 시간을 줄이기 위한 어떠한 방법을 사용하는지 - 최종 응답 데이터는 스트리밍 처리를 통해 사용자 체감을 줄입니다.
    - [https://www.genspark.ai](https://www.genspark.ai/)
    - 구글 AI 검색 : [https://youtu.be/dVsiusLQy5Q](https://youtu.be/dVsiusLQy5Q)
    - 구글 Gemini Live : [https://youtu.be/798VKff1v2U](https://youtu.be/798VKff1v2U)
    - 커스텀칩 : groq (초당 750토큰 생성), cerebras (초당 1,800토큰 생성)
    [https://cerebras.ai/blog/introducing-cerebras-inference-ai-at-instant-speed](https://cerebras.ai/blog/introducing-cerebras-inference-ai-at-instant-speed)